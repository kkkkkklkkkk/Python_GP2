{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GvPBbPIxmy3z",
        "outputId": "c11b3aef-52e4-4ded-f723-8a69659ab5d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [60.9 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,289 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,976 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,528 kB]\n",
            "Get:16 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.2 kB]\n",
            "Get:17 https://cli.github.com/packages stable/main amd64 Packages [344 B]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,827 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,441 kB]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,125 kB]\n",
            "Get:21 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,168 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,857 kB]\n",
            "Fetched 37.5 MB in 15s (2,536 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor chromium-browser libfuse3-3 libudev1 snapd squashfs-tools\n",
            "  systemd-hwe-hwdb udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver libfuse3-3 snapd\n",
            "  squashfs-tools systemd-hwe-hwdb udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 8 newly installed, 0 to remove and 66 not upgraded.\n",
            "Need to get 34.2 MB of archives.\n",
            "After this operation, 134 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.17 [76.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.17 [1,557 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.71+ubuntu22.04 [31.6 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.6 [3,668 B]\n",
            "Fetched 34.2 MB in 2s (17.2 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.17_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.17) over (249.11-0ubuntu3.12) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.17) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 126875 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_249.11-0ubuntu3.17_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.17) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.71+ubuntu22.04_amd64.deb ...\n",
            "Unpacking snapd (2.71+ubuntu22.04) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.17) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.71+ubuntu22.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 127105 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.6_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.6) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.6) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.17) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.38.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Collecting trio<1.0,>=0.31.0 (from selenium)\n",
            "  Downloading trio-0.32.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2025.10.5 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.10.5)\n",
            "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (3.10)\n",
            "Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
            "  Downloading wsproto-1.3.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
            "Downloading selenium-4.38.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.32.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.0/512.0 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.3.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.38.0 trio-0.32.0 trio-websocket-0.12.2 wsproto-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HUPcjaCZ4Ldb",
        "outputId": "96810e77-c4a3-43f2-a5b7-5bfb0dfb827d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 4/51 [02:15<26:25, 33.74s/it]"
          ]
        }
      ],
      "source": [
        "options = Options()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\")\n",
        "\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "def parser(driver):\n",
        "    page = driver.page_source\n",
        "    soup = BeautifulSoup(page, 'html.parser')\n",
        "    containers = soup.find_all('li', class_='ipc-metadata-list-summary-item')\n",
        "\n",
        "    titles = []\n",
        "    years = []\n",
        "    ratings = []\n",
        "    durations = []\n",
        "    age_limits = []\n",
        "    movie_ids = []\n",
        "\n",
        "    for container in containers:\n",
        "        titl = container.find('h3', class_='ipc-title__text')\n",
        "        if titl:\n",
        "            title_text = titl.text.strip()\n",
        "            clean_title = re.sub(r'^\\d+\\.\\s*', '', title_text)\n",
        "            titles.append(clean_title)\n",
        "        else:\n",
        "            titles.append(None)\n",
        "\n",
        "        metadata = container.find_all('span', class_='sc-caa65599-7')\n",
        "        year = metadata[0].text.strip() if len(metadata) > 0 else None\n",
        "        years.append(year)\n",
        "        duration = metadata[1].text.strip() if len(metadata) > 1 else None\n",
        "        durations.append(duration)\n",
        "        age_limit = metadata[2].text.strip() if len(metadata) > 2 else None\n",
        "        age_limits.append(age_limit)\n",
        "\n",
        "        rating = container.find('span', class_='ipc-rating-star--rating')\n",
        "        if rating:\n",
        "            ratings.append(rating.text.strip())\n",
        "        else:\n",
        "            ratings.append(None)\n",
        "\n",
        "        link = container.find('a', class_='ipc-title-link-wrapper')\n",
        "        if link and 'href' in link.attrs:\n",
        "            href = link['href']\n",
        "            id = re.search(r'/title/(tt\\d+)/', href)\n",
        "            if id:\n",
        "                movie_ids.append(id.group(1))\n",
        "            else:\n",
        "                movie_ids.append(None)\n",
        "        else:\n",
        "            movie_ids.append(None)\n",
        "\n",
        "    return titles, years, ratings, durations, age_limits, movie_ids\n",
        "\n",
        "def get_movies(year, num=250):\n",
        "    all_titles = []\n",
        "    all_years = []\n",
        "    all_ratings = []\n",
        "    all_durations = []\n",
        "    all_age_limits = []\n",
        "    all_movie_ids = []\n",
        "\n",
        "    url = f\"https://www.imdb.com/search/title/?title_type=feature&release_date={year}-01-01,{year}-12-31&sort=num_votes,desc\"\n",
        "    driver.get(url)\n",
        "    time.sleep(3)\n",
        "\n",
        "    last = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    while True:\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        time.sleep(2)\n",
        "        new = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "        if new == last:\n",
        "            break\n",
        "        last = new\n",
        "\n",
        "    collected = 0\n",
        "    click = 0\n",
        "\n",
        "    while collected < num and click < 10:\n",
        "        titles, years, ratings, durations, age_limits, movie_ids = parser(driver)\n",
        "\n",
        "\n",
        "\n",
        "        current = set(all_titles)\n",
        "        for title, year_val, rating, duration, age_limit, movie_id in zip(titles, years, ratings, durations, age_limits, movie_ids):\n",
        "            if title not in current:\n",
        "                all_titles.append(title)\n",
        "                all_years.append(year_val)\n",
        "                all_ratings.append(rating)\n",
        "                all_durations.append(duration)\n",
        "                all_age_limits.append(age_limit)\n",
        "                all_movie_ids.append(movie_id)\n",
        "\n",
        "        collected = len(all_titles)\n",
        "\n",
        "\n",
        "\n",
        "        if collected >= num:\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            more = WebDriverWait(driver, 10).until(\n",
        "                EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.ipc-see-more__button\"))\n",
        "            )\n",
        "            driver.execute_script(\"arguments[0].click();\", more)\n",
        "            time.sleep(3)\n",
        "\n",
        "            last = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "            while True:\n",
        "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "                time.sleep(2)\n",
        "                new = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "                if new == last:\n",
        "                    break\n",
        "                last = new\n",
        "\n",
        "            click += 1\n",
        "        except:\n",
        "\n",
        "            break\n",
        "\n",
        "    return all_titles[:num], all_years[:num], all_ratings[:num], all_durations[:num], all_age_limits[:num], all_movie_ids[:num]\n",
        "\n",
        "all = []\n",
        "\n",
        "for year in tqdm(range(1974, 2025)):\n",
        "    titles, years_list, ratings, durations, age_limits, movie_ids = get_movies(year, 200)\n",
        "\n",
        "    for title, year_val, rating, duration, age_limit, movie_id in zip(titles, years_list, ratings, durations, age_limits, movie_ids):\n",
        "        all.append({\n",
        "            'title': title,\n",
        "            'year': year_val,\n",
        "            'rating_IMDB': rating,\n",
        "            'duration': duration,\n",
        "            'age_limit': age_limit,\n",
        "            'movie_id': movie_id\n",
        "        })\n",
        "    time.sleep(2)\n",
        "\n",
        "driver.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NcBmd2u2dhnf"
      },
      "outputs": [],
      "source": [
        "imdb_df = pd.DataFrame(all)\n",
        "imdb_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HKDQa1xeHG7"
      },
      "outputs": [],
      "source": [
        "imdb_df['year'] = imdb_df['year'].astype(int)\n",
        "imdb_df['rating_IMDB'] = imdb_df['rating_IMDB'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8o7Hb6uVuI5U"
      },
      "outputs": [],
      "source": [
        "imdb_df['duration'] = (\n",
        "    imdb_df['duration'].str.extract(r'(\\d+)h').fillna(0)[0].astype(int) * 60 +\n",
        "    imdb_df['duration'].str.extract(r'(\\d+)m').fillna(0)[0].astype(int)\n",
        ").astype(int)\n",
        "imdb_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avC-EbA00HVP"
      },
      "outputs": [],
      "source": [
        "imdb_df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDCYmQT-T6EC"
      },
      "outputs": [],
      "source": [
        "imdb_df.to_csv('временный_датасет.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vQY3M8haSSOy"
      },
      "outputs": [],
      "source": [
        "API_KEY = \"3976e5da53f5c0777897995e4e29ac9b\"\n",
        "\n",
        "def get_tmdb(year, page=1):\n",
        "    url = f\"https://api.themoviedb.org/3/discover/movie\"\n",
        "    params = {\n",
        "        'api_key': API_KEY,\n",
        "        'language': 'en-US',\n",
        "        'sort_by': 'vote_count.desc',\n",
        "        'primary_release_year': year,\n",
        "        'page': page\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    return response.json()\n",
        "\n",
        "def details(movie_id):\n",
        "    url = f\"https://api.themoviedb.org/3/movie/{movie_id}\"\n",
        "    params = {\n",
        "        'api_key': API_KEY,\n",
        "        'language': 'en-US',\n",
        "        'append_to_response': 'release_dates'\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    return response.json()\n",
        "\n",
        "def age(release_dates):\n",
        "    if not release_dates or \"results\" not in release_dates:\n",
        "        return None\n",
        "    results = release_dates[\"results\"]\n",
        "\n",
        "    for res in results:\n",
        "        if res.get(\"iso_3166_1\") == \"US\":\n",
        "            rels = res.get(\"release_dates\", [])\n",
        "            if rels:\n",
        "                cert = rels[0].get(\"certification\")\n",
        "                if cert:\n",
        "                    return cert\n",
        "\n",
        "    for res in results:\n",
        "        for rd in res.get(\"release_dates\", []):\n",
        "            cert = rd.get(\"certification\")\n",
        "            if cert:\n",
        "                return cert\n",
        "    return None\n",
        "\n",
        "tmdb_data = []\n",
        "count = 0\n",
        "start_time = time.time()\n",
        "\n",
        "period = 2025 - 1974\n",
        "total_movies = period * 200\n",
        "\n",
        "with tqdm(total=total_movies) as pbar:\n",
        "    for year in range(1974, 2025):\n",
        "        try:\n",
        "            collected = 0\n",
        "            page = 1\n",
        "\n",
        "            while collected < 200:\n",
        "                if count >= 40:\n",
        "                    time_passed = time.time() - start_time\n",
        "                    if time_passed < 10:\n",
        "                        sleep_time = 10 - time_passed\n",
        "                        time.sleep(sleep_time)\n",
        "                    count = 0\n",
        "                    start_time = time.time()\n",
        "\n",
        "                data = get_tmdb(year, page)\n",
        "                count += 1\n",
        "\n",
        "                if not data.get('results'):\n",
        "                    break\n",
        "\n",
        "                for movie in data['results']:\n",
        "                    if collected >= 200:\n",
        "                        break\n",
        "\n",
        "                    if count >= 40:\n",
        "                        time_passed = time.time() - start_time\n",
        "                        if time_passed < 10:\n",
        "                            sleep_time = 10 - time_passed\n",
        "                            time.sleep(sleep_time)\n",
        "                        count = 0\n",
        "                        start_time = time.time()\n",
        "\n",
        "                    movie_details = details(movie['id'])\n",
        "                    count += 1\n",
        "\n",
        "                    countries = [country['name'] for country in movie_details.get('production_countries', [])]\n",
        "\n",
        "                    budget = movie_details.get('budget')\n",
        "                    revenue = movie_details.get('revenue')\n",
        "                    duration = movie_details.get('runtime')\n",
        "\n",
        "                    tmdb_data.append({\n",
        "                        'title': movie['title'],\n",
        "                        'year': year,\n",
        "                        'country': ', '.join(countries) if countries else None,\n",
        "                        'rating_TMDB': movie['vote_average'],\n",
        "                        'age_rating': age(movie_details.get('release_dates')),\n",
        "                        'genres': ', '.join([genre['name'] for genre in movie_details.get('genres', [])]) if movie_details.get('genres') else None,\n",
        "                        'revenue': revenue if revenue != 0 else None,\n",
        "                        'budget': budget if budget != 0 else None,\n",
        "                        'duration': duration if duration != 0 else None\n",
        "                    })\n",
        "\n",
        "                    collected += 1\n",
        "                    pbar.update(1)\n",
        "                    time.sleep(0.1)\n",
        "\n",
        "                page += 1\n",
        "                if page > data['total_pages']:\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            time.sleep(1)\n",
        "\n",
        "tmdb_df = pd.DataFrame(tmdb_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDBvKU4HTiUD"
      },
      "outputs": [],
      "source": [
        "tmdb_df.to_csv('временный_датасет2.0.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WD6xiGhHqOtD"
      },
      "outputs": [],
      "source": [
        "tmdb_df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yP3GoD-Xr9NH"
      },
      "outputs": [],
      "source": [
        "tmdb_df['title'] = tmdb_df['title'].str.replace(r'[^\\w\\s-]', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QSBGjy64sVct"
      },
      "outputs": [],
      "source": [
        "tmdb_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ywF1NMPsj8J"
      },
      "outputs": [],
      "source": [
        "data = pd.merge(\n",
        "    imdb_df[['title', 'year', 'rating_IMDB', 'duration', 'age_limit', 'movie_id']],\n",
        "    tmdb_df[['title', 'country', 'rating_TMDB', 'age_rating', 'genres', 'revenue', 'budget']],\n",
        "    on='title',\n",
        "    how='left',\n",
        ")\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro0qpkZXkTZc"
      },
      "outputs": [],
      "source": [
        "data['title'].duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai7re9YSkbEI"
      },
      "outputs": [],
      "source": [
        "data = data.drop_duplicates(subset=['title'], keep='first')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Wc24e_Eiwysh"
      },
      "outputs": [],
      "source": [
        "data['rating'] = data[['rating_IMDB', 'rating_TMDB']].mean(axis=1, skipna=True)\n",
        "data = data.drop(['rating_IMDB', 'rating_TMDB'], axis=1)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "My18VqmrNuc9"
      },
      "outputs": [],
      "source": [
        "data['age_limit'] = data['age_limit'].fillna(data['age_rating'])\n",
        "data = data.drop(['age_rating'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_gnUfG_NyhD"
      },
      "outputs": [],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ3LQUKb6oC0"
      },
      "outputs": [],
      "source": [
        "def get_countries(movie_id, delay_range=(1, 3)):\n",
        "    url = f\"https://www.imdb.com/title/{movie_id}/\"\n",
        "\n",
        "    time.sleep(random.uniform(*delay_range))\n",
        "\n",
        "    try:\n",
        "        session = requests.Session()\n",
        "        session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        })\n",
        "\n",
        "        response = session.get(url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        strana = soup.find('li', {\n",
        "            'data-testid': 'title-details-origin'\n",
        "        })\n",
        "\n",
        "        if strana:\n",
        "            strana_links = strana.find_all('a', {\n",
        "                'class': 'ipc-metadata-list-item__list-content-item--link'\n",
        "            })\n",
        "            countries = [link.get_text(strip=True) for link in strana_links]\n",
        "            return countries\n",
        "\n",
        "        return []\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        return []\n",
        "\n",
        "def parser_stran(data, country_col='country', movie_id_col='movie_id', delay_range=(1, 3)):\n",
        "    df = data.copy()\n",
        "\n",
        "    nan_mask = df[country_col].isna()\n",
        "    nan_ind = df[nan_mask].index\n",
        "    total_nan = len(nan_ind)\n",
        "\n",
        "    for i, idx in enumerate(tqdm(nan_ind), 1):\n",
        "        movie_id = df.loc[idx, movie_id_col]\n",
        "\n",
        "        if pd.notna(movie_id) and movie_id != '':\n",
        "            countries = get_countries(movie_id, delay_range)\n",
        "\n",
        "            if countries:\n",
        "                df.loc[idx, country_col] = ', '.join(countries)\n",
        "            else:\n",
        "                df.loc[idx, country_col] = 'Не найдено'\n",
        "    return df\n",
        "\n",
        "\n",
        "data = parser_stran(\n",
        "    data,\n",
        "    country_col='country',\n",
        "    movie_id_col='movie_id',\n",
        "    delay_range=(1, 2)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95Div0rtjVqL"
      },
      "outputs": [],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAZ3YncH8TOJ"
      },
      "outputs": [],
      "source": [
        "def get_genres(movie_id, delay=(1, 3)):\n",
        "    url = f\"https://www.imdb.com/title/{movie_id}/\"\n",
        "\n",
        "    time.sleep(random.uniform(*delay))\n",
        "\n",
        "    try:\n",
        "        session = requests.Session()\n",
        "        session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "        })\n",
        "\n",
        "        response = session.get(url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        genres_elem = soup.find('li', {'data-testid': 'storyline-genres'})\n",
        "        if genres_elem:\n",
        "            genre_links = genres_elem.find_all('a', class_='ipc-metadata-list-item__list-content-item--link')\n",
        "            genres = [link.get_text(strip=True) for link in genre_links]\n",
        "            if genres:\n",
        "                return genres\n",
        "\n",
        "\n",
        "        genr_links = soup.find_all('a', href=lambda href: href and '/search/title/?genres=' in href)\n",
        "        genres = []\n",
        "        for link in genr_links:\n",
        "            genre_text = link.get_text(strip=True)\n",
        "            if genre_text and genre_text not in genres:\n",
        "                genres.append(genre_text)\n",
        "        if genres:\n",
        "            return genres\n",
        "\n",
        "        return []\n",
        "\n",
        "    except Exception as e:\n",
        "        return []\n",
        "\n",
        "def parse_genres(data, genre_col='genres', movie_id_col='movie_id', delay=(1, 3)):\n",
        "    df = data.copy()\n",
        "\n",
        "    nan_mask = df[genre_col].isna()\n",
        "    nan_indices = df[nan_mask].index\n",
        "    total_nan = len(nan_indices)\n",
        "\n",
        "    for idx in tqdm(nan_indices):\n",
        "        movie_id = df.loc[idx, movie_id_col]\n",
        "\n",
        "        if pd.notna(movie_id) and movie_id != '':\n",
        "            genres = get_genres(movie_id, delay)\n",
        "\n",
        "            if genres:\n",
        "                df.loc[idx, genre_col] = ', '.join(genres)\n",
        "\n",
        "    return df\n",
        "\n",
        "data = parse_genres(\n",
        "    data,\n",
        "    genre_col='genres',\n",
        "    movie_id_col='movie_id',\n",
        "    delay=(1, 2)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KruLHkSr8UYc"
      },
      "outputs": [],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bU5MwG1dG49A"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmGRkIRQ-ZkA"
      },
      "outputs": [],
      "source": [
        "def parse_money(text):\n",
        "    if not text:\n",
        "        return None\n",
        "    try:\n",
        "        clean = re.sub(r'[^\\d.]', '', text)\n",
        "        return float(clean) if clean else None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def get_box_office(movie_id, delay=(1, 3)):\n",
        "    url = f\"https://www.boxofficemojo.com/title/{movie_id}/\"\n",
        "\n",
        "    time.sleep(random.uniform(*delay))\n",
        "\n",
        "    try:\n",
        "        session = requests.Session()\n",
        "        session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "        })\n",
        "\n",
        "        response = session.get(url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        revenue = None\n",
        "        budget = None\n",
        "\n",
        "\n",
        "        for pattern in ['Worldwide', 'Worldwide Gross']:\n",
        "            elements = soup.find_all(string=re.compile(pattern, re.IGNORECASE))\n",
        "            for element in elements:\n",
        "                parent = element.parent\n",
        "                for _ in range(5):\n",
        "                    if not parent:\n",
        "                        break\n",
        "                    money_span = parent.find('span', class_='money')\n",
        "                    if money_span:\n",
        "                        revenue = parse_money(money_span.get_text(strip=True))\n",
        "                        break\n",
        "                    parent = parent.parent\n",
        "                if revenue:\n",
        "                    break\n",
        "            if revenue:\n",
        "                break\n",
        "\n",
        "\n",
        "        for pattern in ['Budget', 'Production Budget']:\n",
        "            elements = soup.find_all(string=re.compile(pattern, re.IGNORECASE))\n",
        "            for element in elements:\n",
        "                parent = element.parent\n",
        "                for _ in range(3):\n",
        "                    if not parent:\n",
        "                        break\n",
        "                    money_span = parent.find('span', class_='money')\n",
        "                    if money_span:\n",
        "                        budget = parse_money(money_span.get_text(strip=True))\n",
        "                        break\n",
        "                    parent = parent.parent\n",
        "                if budget:\n",
        "                    break\n",
        "            if budget:\n",
        "                break\n",
        "\n",
        "        return {'revenue': revenue, 'budget': budget}\n",
        "\n",
        "    except Exception:\n",
        "        return {'revenue': None, 'budget': None}\n",
        "\n",
        "def parse_box_office(data, revenue_col='revenue', budget_col='budget', movie_id_col='movie_id', delay=(1, 3)):\n",
        "    df = data.copy()\n",
        "\n",
        "\n",
        "    nan_revenue = df[revenue_col].isna()\n",
        "    nan_budget = df[budget_col].isna()\n",
        "    nan_indices = df[nan_revenue | nan_budget].index\n",
        "\n",
        "    for idx in tqdm(nan_indices, desc=\"\"):\n",
        "        movie_id = df.loc[idx, movie_id_col]\n",
        "\n",
        "        if pd.notna(movie_id) and movie_id != '':\n",
        "            result = get_box_office(movie_id, delay)\n",
        "\n",
        "            if pd.isna(df.loc[idx, revenue_col]) and result['revenue']:\n",
        "                df.loc[idx, revenue_col] = result['revenue']\n",
        "\n",
        "            if pd.isna(df.loc[idx, budget_col]) and result['budget']:\n",
        "                df.loc[idx, budget_col] = result['budget']\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "data = parse_box_office(\n",
        "    data,\n",
        "    revenue_col='revenue',\n",
        "    budget_col='budget',\n",
        "    movie_id_col='movie_id',\n",
        "    delay=(1, 2)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUmH7QAw9Pxh"
      },
      "outputs": [],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnRHFq0E_HLN"
      },
      "outputs": [],
      "source": [
        "def get_imdb_box_office(movie_id, delay=(1, 3)):\n",
        "    url = f\"https://www.imdb.com/title/{movie_id}/\"\n",
        "\n",
        "    time.sleep(random.uniform(*delay))\n",
        "\n",
        "    try:\n",
        "        session = requests.Session()\n",
        "        session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "        })\n",
        "\n",
        "        response = session.get(url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        revenue = None\n",
        "        budget = None\n",
        "\n",
        "\n",
        "        box_office = soup.find('div', {'data-testid': 'title-boxoffice-section'})\n",
        "\n",
        "        if box_office:\n",
        "\n",
        "            worldwide = box_office.find('li', {\n",
        "                'data-testid': 'title-boxoffice-cumulativeworldwidegross'\n",
        "            })\n",
        "            if worldwide:\n",
        "                revenue_span = worldwide.find('span', {\n",
        "                    'class': 'ipc-metadata-list-item__list-content-item'\n",
        "                })\n",
        "                if revenue_span:\n",
        "                    revenue = revenue_span.get_text(strip=True)\n",
        "\n",
        "\n",
        "        budget_elem = soup.find('li', {'data-testid': 'title-boxoffice-budget'})\n",
        "        if budget_elem:\n",
        "            budget_span = budget_elem.find('span', {\n",
        "                'class': 'ipc-metadata-list-item__list-content-item'\n",
        "            })\n",
        "            if budget_span:\n",
        "                budget = budget_span.get_text(strip=True)\n",
        "\n",
        "        return {'revenue': revenue, 'budget': budget}\n",
        "\n",
        "    except Exception:\n",
        "        return {'revenue': None, 'budget': None}\n",
        "\n",
        "def parse_imdb_box_office(data, revenue_col='revenue', budget_col='budget', movie_id_col='movie_id', delay=(1, 3)):\n",
        "    df = data.copy()\n",
        "\n",
        "\n",
        "    nan_revenue = df[revenue_col].isna()\n",
        "    nan_budget = df[budget_col].isna()\n",
        "    nan_indices = df[nan_revenue | nan_budget].index\n",
        "\n",
        "    for idx in tqdm(nan_indices, desc=\"\"):\n",
        "        movie_id = df.loc[idx, movie_id_col]\n",
        "\n",
        "        if pd.notna(movie_id) and movie_id != '':\n",
        "            result = get_imdb_box_office(movie_id, delay)\n",
        "\n",
        "            if pd.isna(df.loc[idx, revenue_col]) and result['revenue']:\n",
        "                df.loc[idx, revenue_col] = result['revenue']\n",
        "\n",
        "            if pd.isna(df.loc[idx, budget_col]) and result['budget']:\n",
        "                df.loc[idx, budget_col] = result['budget']\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "data = parse_imdb_box_office(\n",
        "    data,\n",
        "    revenue_col='revenue',\n",
        "    budget_col='budget',\n",
        "    movie_id_col='movie_id',\n",
        "    delay=(1, 2)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr3NnZK4s7m_"
      },
      "outputs": [],
      "source": [
        "exc = {\n",
        "    '€': {2000: 0.94, 2004: 0.80, 2008: 0.68, 2010: 0.75, 2015: 0.90, 2020: 0.88, 2024: 0.92},\n",
        "    '£': {1980: 2.33, 1990: 1.65, 2000: 1.52, 2010: 1.54, 2020: 1.29},\n",
        "    'DEM': {1975: 2.50, 1985: 2.90, 1990: 1.65, 1995: 1.45, 1999: 1.06},\n",
        "    'FRF': {1980: 4.20, 1990: 5.40, 1995: 5.05, 2000: 6.56},\n",
        "    'ITL': {1980: 880.0, 1990: 1200.0, 1995: 1600.0},\n",
        "    'ESP': {1980: 75.0, 1990: 100.0},\n",
        "    'NLG': {1977: 2.35, 1990: 1.82},\n",
        "    'IEP': {1990: 0.77},\n",
        "    'FIM': {1980: 3.86, 1990: 3.91, 2000: 5.95},\n",
        "    'DKK': {1990: 6.4, 2000: 7.0},\n",
        "    'SEK': {1980: 4.23, 1990: 6.0, 2000: 9.0},\n",
        "    'NOK': {1980: 5.0, 1990: 6.3, 2000: 8.0},\n",
        "    '¥': {1980: 225, 1990: 145, 2000: 108, 2010: 88, 2020: 106},\n",
        "    'CN¥': {1980: 1.5, 1990: 4.7, 2000: 8.3, 2010: 6.8, 2020: 6.9},\n",
        "    '₹': {1980: 8.0, 1990: 17.5, 2000: 45.0, 2010: 45.7, 2020: 74.0},\n",
        "}\n",
        "\n",
        "def convert(row):\n",
        "    val = str(row['budget'])\n",
        "    year = int(row['year']) if not pd.isna(row['year']) else None\n",
        "    if pd.isna(val) or year is None:\n",
        "        return None\n",
        "\n",
        "\n",
        "    for cur in exc.keys():\n",
        "        if cur in val:\n",
        "            n = re.sub(r\"[^\\d.]\", \"\", val)\n",
        "            if not n:\n",
        "                return None\n",
        "            n = float(n)\n",
        "\n",
        "\n",
        "            rates = exc[cur]\n",
        "            near = min(rates.keys(), key=lambda y: abs(y - year))\n",
        "            rate = rates[near]\n",
        "\n",
        "            return n / rate\n",
        "\n",
        "    n = re.sub(r\"[^\\d.]\", \"\", val)\n",
        "    return float(n) if n else None\n",
        "\n",
        "data['budget'] = data.apply(convert, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_r5ZoF1Cncg"
      },
      "outputs": [],
      "source": [
        "def clean_money(value):\n",
        "    if pd.isna(value):\n",
        "        return value\n",
        "    value = str(value)\n",
        "    cleaned = re.sub(r'[\\$,]', '', value)\n",
        "    try:\n",
        "        return float(cleaned)\n",
        "    except ValueError:\n",
        "        return value\n",
        "\n",
        "for col in ['budget', 'revenue']:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].apply(clean_money)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqDntqE1azSQ"
      },
      "outputs": [],
      "source": [
        "data.to_csv(\"итоговый_датасет.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# Загрузка файла с компьютера\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Получение имени файла\n",
        "filename = list(uploaded.keys())[0]\n",
        "print(f\"Загружен файл: {filename}\")\n",
        "\n",
        "# Чтение файла в pandas DataFrame\n",
        "data = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "\n",
        "# Показать первые строки\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "a67oQB1tCLAO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}